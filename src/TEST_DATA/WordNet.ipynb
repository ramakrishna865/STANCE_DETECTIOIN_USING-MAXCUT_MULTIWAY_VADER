{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#wordnet\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Convert words to lowercase\n",
        "    words = [word.lower() for word in words]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return words\n",
        "\n",
        "def get_sentiment_score(word, words):\n",
        "    synsets = wn.synsets(word)\n",
        "    if synsets:\n",
        "        # Check if there is any positive or negative sentiment in the synsets\n",
        "        for synset in synsets:\n",
        "            # Check if the synset contains any positive or negative word\n",
        "            for lemma in synset.lemmas():\n",
        "                if lemma.antonyms():  # If word has an antonym, it's opposite in sentiment\n",
        "                    antonyms = lemma.antonyms()\n",
        "                    # Check if the antonym is in the sentence\n",
        "                    for antonym in antonyms:\n",
        "                        if antonym.name() in words:\n",
        "                            return -1  # Negative sentiment due to negation\n",
        "                elif lemma.name() == word:\n",
        "                    return 1  # Positive sentiment (if the word is a direct synonym)\n",
        "    return 0  # Neutral sentiment\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    # Preprocess the text\n",
        "    words = preprocess_text(text)\n",
        "\n",
        "    # Initialize variables to count sentiment scores\n",
        "    positive_scores = []\n",
        "    negative_scores = []\n",
        "    word_sentiment_scores = {}\n",
        "\n",
        "    # Analyze sentiment scores for each word\n",
        "    for word in words:\n",
        "        # Calculate sentiment scores using WordNet\n",
        "        sentiment_score = get_sentiment_score(word, words)\n",
        "\n",
        "        # Store sentiment score for each word\n",
        "        word_sentiment_scores[word] = sentiment_score\n",
        "\n",
        "        # Update positive and negative scores\n",
        "        if sentiment_score > 0:\n",
        "            positive_scores.append(sentiment_score)\n",
        "        elif sentiment_score < 0:\n",
        "            negative_scores.append(sentiment_score)\n",
        "\n",
        "    # Calculate average positive and negative scores\n",
        "    if positive_scores:\n",
        "        avg_positive_score = sum(positive_scores) / len(positive_scores)\n",
        "    else:\n",
        "        avg_positive_score = 0\n",
        "\n",
        "    if negative_scores:\n",
        "        avg_negative_score = sum(negative_scores) / len(negative_scores)\n",
        "    else:\n",
        "        avg_negative_score = 0\n",
        "\n",
        "    # Calculate overall sentiment score for the sentence\n",
        "    overall_sentiment_score = avg_positive_score - avg_negative_score\n",
        "\n",
        "    return avg_positive_score, avg_negative_score, overall_sentiment_score\n",
        "\n",
        "# Example data\n",
        "data = [\n",
        "    {\"author_id\": 1, \"text\": \"The movie was not good. It was actually quite bad.\"},\n",
        "    {\"author_id\": 2, \"text\": \"I love this book! It's fantastic.\"},\n",
        "    {\"author_id\": 3, \"text\": \"The weather today is terrible.\"},\n",
        "    {\"author_id\": 4, \"text\": \"The concert was amazing.\"},\n",
        "]\n",
        "\n",
        "# Write sentiment analysis results to a CSV file\n",
        "with open(\"sentiment_analysis_results.csv\", \"w\", newline=\"\") as csvfile:\n",
        "    fieldnames = [\"author_id\", \"text\", \"avg_positive_score\", \"avg_negative_score\", \"overall_sentiment_score\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "\n",
        "    for entry in data:\n",
        "        author_id = entry[\"author_id\"]\n",
        "        text = entry[\"text\"]\n",
        "\n",
        "        # Perform sentiment analysis\n",
        "        avg_positive_score, avg_negative_score, overall_sentiment_score = analyze_sentiment(text)\n",
        "\n",
        "        # Write to CSV\n",
        "        writer.writerow({\n",
        "            \"author_id\": author_id,\n",
        "            \"text\": text,\n",
        "            \"avg_positive_score\": avg_positive_score,\n",
        "            \"avg_negative_score\": avg_negative_score,\n",
        "            \"overall_sentiment_score\": overall_sentiment_score\n",
        "        })\n",
        "\n",
        "print(\"CSV file created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFc-ObVAPL8m",
        "outputId": "be50e2a5-c09f-4c90-b278-fc5a9067b464"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created successfully!\n"
          ]
        }
      ]
    }
  ]
}